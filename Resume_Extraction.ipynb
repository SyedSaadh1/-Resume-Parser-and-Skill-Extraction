{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfquery\n",
        "import pdfquery"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMQh-1tNaBd8",
        "outputId": "71fff904-ec3a-4ec6-9d5f-702a3d8c6521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfquery\n",
            "  Downloading pdfquery-0.4.3.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cssselect>=0.7.1 (from pdfquery)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from pdfquery) (5.2.0)\n",
            "Requirement already satisfied: lxml>=3.0 in /usr/local/lib/python3.10/dist-packages (from pdfquery) (4.9.4)\n",
            "Collecting pdfminer.six (from pdfquery)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyquery>=1.2.2 (from pdfquery)\n",
            "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting roman>=1.4.0 (from pdfquery)\n",
            "  Downloading roman-4.1-py3-none-any.whl (5.5 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->pdfquery) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->pdfquery) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->pdfquery) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pdfquery) (2.21)\n",
            "Building wheels for collected packages: pdfquery\n",
            "  Building wheel for pdfquery (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfquery: filename=pdfquery-0.4.3-py3-none-any.whl size=16780 sha256=c9c51cb5e08ae0e18adf5a262d6f4d45e5042d4b8d134dd7f513361f23644d62\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/a2/41/ca6652543d0fa5762560eaaf0f620a5d6341ec0b9e60996d16\n",
            "Successfully built pdfquery\n",
            "Installing collected packages: roman, cssselect, pyquery, pdfminer.six, pdfquery\n",
            "Successfully installed cssselect-1.2.0 pdfminer.six-20231228 pdfquery-0.4.3 pyquery-2.0.0 roman-4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGc8X9oVY3pT",
        "outputId": "c5fe9129-2914-4154-f399-65c7573e9b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syed Saadh AI/ML Engineer, Hyderabad, India | +91 9000788056 Objective Dynamic AI/ML professional with over 2 years of experience, skilled in machine learning, deep learning, Python, NLP, and front-end technologies. Adept at developing comprehensive technology solutions with a focus on AI integration. Seeking to contribute my diverse skill set to drive innovative AI applications and web-based solutions. Skills ● AI/ML Technologies: Proficient in ML, Deep Learning, TensorFlow, Python, and NLP. ● Programming: Strong skills in Python, JavaScript, HTML, CSS, and React. ● Web Development: Experienced in building user-friendly interfaces. ● API Development: Hands-on experience with ChatGPT, related APIs, and RESTful services. ● Database Technologies: Knowledge in MySql, NoSQL, RDBMS design, and optimizations. ● Design Principles: Familiar with object-oriented and functional design, and best-practice patterns. Roles & Responsibilities ● AI/ML Development: Developed and optimized machine learning models using TensorFlow and Python, focusing on enhancing application functionalities and user experiences. ● AI Strategy Implementation: Played a key role in the planning and execution of AI strategies, aligning them with business objectives and client needs. ● Cross-Functional Collaboration: Worked closely with cross-functional teams to identify areas where AI solutions could signiﬁcantly beneﬁt business operations. ● Documentation and Reporting: Documented development tasks, architectural solutions, and lessons learned to facilitate knowledge sharing and continuous improvement. ● Front-End Development: Utilized JavaScript, React, HTML, and CSS to develop and enhance user interfaces, ensuring seamless integration with AI functionalities. ● API Development and Integration: Developed and integrated APIs, including ChatGPT and other related services, to enhance application capabilities. ● Database Design and Management: Proﬁcient in REST API development, NoSQL database design, and RDBMS optimization to support robust back-end operations. ● Continuous Learning and Innovation: Kept abreast of the latest advancements in AI, ML, and web technologies, continuously experimenting with new algorithms and techniques. saadhsyed1@gmail.com Professional Experience Software Engineer – TRANGLA Guntur, August 2022 – Present ● Developed and managed AI-driven coding tasks for application/product developments. ● Collaborated with cross-functional teams to identify and implement AI solutions. ● Designed and tested AI and ML coding solutions, upholding high ethical standards. ● Participated in functional and process design, prototyping, and training sessions. ● Documented and shared development tasks, solutions architecture, and key learnings. ● Oversaw AI market and competitor assessments by the development team. ● Utilized JavaScript, React, HTML, and CSS for front-end development in AI projects. Data Analyst Intern – PHOENIXGLOBAL Hyderabad, April 2022 – July 2022 ● Spearheaded the development and management of ML-driven coding tasks, driving advancements in application and product development. ● Utilized Python programming language and regression methodologies to forecast house prices, leveraging libraries such as Pandas and Numpy. ● Designed and rigorously tested AI and ML coding solutions, consistently upholding high ethical standards in every aspect of the development process. ● Actively engaged in functional and process design, prototyping, and training sessions, contributing specialized insights and expertise to the overall success of projects within the dynamic landscape of Data Science and Machine Learning. ● Documented and shared development tasks, solutions architecture, and key learnings, ensuring effective knowledge dissemination within the team. ● Demonstrated expertise in utilizing Python, Jupyter Notebook, and Google Colab. ● Assumed a leadership position in guiding the project, overseeing the computation of house prices, and implementing strategic measures to improve prediction accuracy. Projects AI/ML Project: Resume Parser and Skill Extraction Project Overview: Developed an advanced Resume Parser and Skill Extraction system using AI and ML technologies. This tool streamlined the evaluation of candidate proﬁles by eﬃciently parsing resumes and extracting key skills. Role & Responsibilities: ● Implemented machine learning models using Python and TensorFlow for resume analysis and skill extraction. ● Utilized NLP techniques for accurate identiﬁcation and categorization of skills, educational backgrounds, and professional experiences. ● Collaborated with a team to enhance algorithm accuracy and processing eﬃciency. ● Conducted thorough testing and validation to ensure system reliability. ● Integrated the parsing system with existing HR platforms for automated candidate screening. Technologies Used: Python, TensorFlow, NLP, ML Algorithms. Web Development Project: Online Resume Upload Interface Project Overview: Created a responsive web interface for resume uploads, integrating with the AI-based Resume Parser for real-time parsing and skill extraction. Role & Responsibilities: ● Designed the front-end using React, JavaScript, HTML, and CSS, focusing on user experience and interface responsiveness. ● Implemented back-end functionalities for secure resume uploading and management. ● Integrated the web interface with the AI Resume Parser for immediate processing. ● Ensured compatibility across various browsers and mobile devices. Technologies Used: JavaScript, React, HTML, CSS, RESTful APIs. Education Qualiﬁcation COURSE INSTITUTION EXAMINATION AUTHORITY YEAR OF PASSING CGPA B.Tech XII X Gandhi Institute Of Technology Management (Gitam University) -CSE Sri Chaitanya Junior College, Ongole Gowtham Model School, Ongole UGC 2019 - 2023 85% BIEAP 2017-2019 87% SSC 2016-2017 92%\n"
          ]
        }
      ],
      "source": [
        "import pdfquery\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "pdf = pdfquery.PDFQuery(\"/content/Saadh Syed_Resume.pdf\")\n",
        "\n",
        "\n",
        "pdf.load()\n",
        "text = pdf.pq(\"LTTextLineHorizontal\").text()\n",
        "doc = nlp(text)\n",
        "\n",
        "print(doc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-iZST95ZwIT",
        "outputId": "1a5fb2a8-0c8f-4b04-8431-59d6deb50bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syed Saadh AI/ML Engineer PERSON\n",
            "Hyderabad GPE\n",
            "India GPE\n",
            "2 years DATE\n",
            "NLP ORG\n",
            "AI ORG\n",
            "AI EVENT\n",
            "AI/ML Technologies ORG\n",
            "ML GPE\n",
            "Deep Learning GPE\n",
            "TensorFlow PRODUCT\n",
            "NLP ORG\n",
            "Python GPE\n",
            "JavaScript PRODUCT\n",
            "HTML ORG\n",
            "CSS ORG\n",
            "MySql GPE\n",
            "NoSQL GPE\n",
            "Familiar PERSON\n",
            "Roles & Responsibilities ● AI/ML Development ORG\n",
            "TensorFlow PRODUCT\n",
            "AI ORG\n",
            "● Cross-Functional Collaboration: Worked ORG\n",
            "AI ORG\n",
            "Front-End Development: Utilized JavaScript ORG\n",
            "CSS ORG\n",
            "AI ORG\n",
            "API Development and Integration ORG\n",
            "Database Design and Management: Proﬁcient ORG\n",
            "NoSQL GPE\n",
            "Continuous Learning PERSON\n",
            "AI GPE\n",
            "ML ORG\n",
            "August 2022 DATE\n",
            "AI ORG\n",
            "AI ORG\n",
            "ML ORG\n",
            "Oversaw AI PERSON\n",
            "CSS ORG\n",
            "AI ORG\n",
            "Analyst Intern PERSON\n",
            "April 2022 DATE\n",
            "July 2022 DATE\n",
            "Pandas ORG\n",
            "Numpy NORP\n",
            "AI ORG\n",
            "ML ORG\n",
            "Data Science and Machine Learning ORG\n",
            "Jupyter Notebook PERSON\n",
            "Google Colab ORG\n",
            "AI/ML Project ORG\n",
            "Resume Parser PERSON\n",
            "Skill Extraction Project Overview ORG\n",
            "Resume Parser PERSON\n",
            "Skill Extraction ORG\n",
            "AI ORG\n",
            "ML ORG\n",
            "Role & Responsibilities ORG\n",
            "TensorFlow PRODUCT\n",
            "NLP ORG\n",
            "TensorFlow ORG\n",
            "NLP ORG\n",
            "ML Algorithms PERSON\n",
            "AI ORG\n",
            "Resume Parser ORG\n",
            "Role & Responsibilities ORG\n",
            "JavaScript PRODUCT\n",
            "CSS ORG\n",
            "JavaScript ORG\n",
            "CSS ORG\n",
            "Sri Chaitanya Junior College ORG\n",
            "Gowtham Model School ORG\n",
            "2019 - 2023 DATE\n",
            "85% PERCENT\n",
            "2017-2019 DATE\n",
            "87% PERCENT\n",
            "2016-2017 DATE\n",
            "92% PERCENT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfquery\n",
        "import spacy\n",
        "\n",
        "pdf = pdfquery.PDFQuery(\"/content/Saadh Syed_Resume.pdf\")\n",
        "\n",
        "\n",
        "pdf.load()\n",
        "text = pdf.pq(\"LTTextLineHorizontal\").text()\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "\n",
        "person_names = []\n",
        "\n",
        "\n",
        "for entity in doc.ents:\n",
        "\n",
        "    if entity.label_ == \"PERSON\":\n",
        "\n",
        "        person_names.append(entity.text)\n",
        "\n",
        "\n",
        "if person_names:\n",
        "    print(person_names[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm13YD-4afdE",
        "outputId": "82010b11-6ae6-4b25-dc03-8f982f4cc584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syed Saadh AI/ML Engineer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzxzAU1Wsdb-",
        "outputId": "540e4a41-0af0-4d63-e44d-bd1660f87baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m163.8/232.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_names_from_pdf(pdf_path):\n",
        "    names = []\n",
        "\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "\n",
        "    name_pattern = re.compile(r'\\b[A-Z][a-z]+(?:\\s[A-Z][a-z]+)+\\b')\n",
        "    names = name_pattern.findall(text)\n",
        "\n",
        "    return names\n",
        "\n",
        "\n",
        "pdf_path = \"/content/Subhani resume new.pdf\"\n",
        "extracted_names = extract_names_from_pdf(pdf_path)\n",
        "\n",
        "print(\"Extracted Names:\")\n",
        "for name in extracted_names:\n",
        "    print(name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2X-5usXtM7m",
        "outputId": "ffc40c60-ae37-4f59-8cda-76b290540cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Names:\n",
            "Quba College\n",
            "Kendriya Vidyalaya\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_names_from_pdf(pdf_path):\n",
        "    names = []\n",
        "\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"PERSON\":\n",
        "            names.append(ent.text)\n",
        "\n",
        "    return names\n",
        "\n",
        "\n",
        "pdf_path = \"/content/Subhani resume new.pdf\"\n",
        "extracted_names = extract_names_from_pdf(pdf_path)\n",
        "\n",
        "print(\"Extracted Names:\")\n",
        "for name in extracted_names:\n",
        "    print(name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6Ym-pwNtdqL",
        "outputId": "5619ccfa-7711-4001-f38d-f7882fa44899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Names:\n",
            "XII Kendriya Vidyalaya\n",
            "Vidyalaya\n",
            "Java\n",
            "Java\n",
            "-Of-Birth  \n",
            "Permanent  Address  \n",
            "Hobbies\n",
            "Gandhi\n",
            "Nagar\n",
            "Kabaddi\n",
            "DECLARATION\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9basHfeaulTW",
        "outputId": "16225c89-0867-4c64-97fc-7482c2e9aca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.22-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.22 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.22 PyMuPDFb-1.23.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import fitz\n",
        "\n",
        "def extract_name_from_pdf(pdf_path):\n",
        "\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "\n",
        "\n",
        "    doc.close()\n",
        "\n",
        "\n",
        "    name_pattern = re.compile(r'\\b[A-Z][a-z]+\\s[A-Z][a-z]+\\b')\n",
        "    match = name_pattern.search(text)\n",
        "\n",
        "    if match:\n",
        "        return match.group()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "pdf_path = input(\"Enter the path to the PDF file: \")\n",
        "\n",
        "\n",
        "name = extract_name_from_pdf(pdf_path)\n",
        "\n",
        "if name:\n",
        "    print(\"Extracted Name:\", name)\n",
        "else:\n",
        "    print(\"Name not found in the PDF file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEbGw3bZxmya",
        "outputId": "b915bbba-8673-4a9c-a966-247727c09290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the PDF file: /content/ShaikAfridiInternResume.pdf\n",
            "Extracted Name: Sk Shahid\n"
          ]
        }
      ]
    }
  ]
}